{"cells":[{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils\n","execution_count":17,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: imutils in /opt/conda/lib/python3.7/site-packages (0.5.4)\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2\nfrom tqdm import tqdm\nfrom scipy.spatial import distance as dist\nimport imutils\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn import decomposition\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n# import mahotas","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Object detection:\n\ndid object detection using opencv by findig edges in the images the extract contours and from contours get image boxes"},{"metadata":{"trusted":true},"cell_type":"code","source":"def findEdges(image):\n    gray = cv2.GaussianBlur(image, (1, 1), 0)\n    edged = cv2.Canny(gray, 100, 400)\n    edged = cv2.dilate(edged, None, iterations=1)\n    edged = cv2.erode(edged, None, iterations=1)\n    return edged\n","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getImgContours(edged):\n    # find contours in the edge map\n    contours = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    contours = imutils.grab_contours(contours)\n    contours = sorted(contours, key=lambda x: cv2.contourArea(x))\n    return contours\n\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getBoxes(contours, orig):\n    boxes = []\n    centers = []\n    for contour in contours:\n        box = cv2.minAreaRect(contour)\n        box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n        box = np.array(box, dtype=\"int\")\n        (tl, tr, br, bl) = box\n        if (dist.euclidean(tl, bl)) > 0 and (dist.euclidean(tl, tr)) > 0:\n            boxes.append(box)\n    return boxes\n","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Data:\n\nLoad_data function that loads images and labels from the Train and Test folders and combines the datasets to return Image-Label pairs \ncombining the Train/Test folders and recreate the dataset ."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"class_names = ['EOSINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\nnb_classes = len(class_names)\nimage_size = (40,40)","execution_count":22,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"\ndef load_data():\n    \n    datasets = ['/kaggle/input/blood-cells/dataset2-master/dataset2-master/images/TRAIN',\n                '/kaggle/input/blood-cells/dataset2-master/dataset2-master/images/TEST' ]    \n    images = []\n    labels = []\n\n    # iterate through training and test sets\n    count=0\n    for dataset in datasets:\n\n        # iterate through folders in each dataset\n        \n        for folder in os.listdir(dataset):\n\n            if folder in ['EOSINOPHIL']: label = 1#[1, 0, 0, 0]\n            elif folder in ['LYMPHOCYTE']: label = 2#[0, 1, 0, 0]\n            elif folder in ['MONOCYTE']: label = 3#[0, 0, 1, 0]\n            elif folder in ['NEUTROPHIL']: label = 4#[0, 0, 0, 1]\n\n            # iterate through each image in folder\n           \n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n\n                # get pathname of each image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n\n                # Open and resize the| img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                 # add padding to the image to better detect cell at the edge\n                image = cv2.copyMakeBorder(image,10,10,10,10,cv2.BORDER_CONSTANT,value=[198, 203, 208])\n                \n                #thresholding the image to get the target cell\n                image1 = cv2.inRange(image,(80, 80, 180),(180, 170, 245))\n                \n                # openning errosion then dilation\n                kernel = np.ones((3, 3), np.uint8)\n                kernel1 = np.ones((5, 5), np.uint8)\n                img_erosion = cv2.erode(image1, kernel, iterations=2)\n                image1 = cv2.dilate(img_erosion, kernel1, iterations=5)\n                \n                #detecting the blood cell\n                edgedImage = findEdges(image1)\n                edgedContours = getImgContours(edgedImage)\n                edgedBoxes =  getBoxes(edgedContours, image.copy())\n                if len(edgedBoxes)==0:\n                    count +=1\n                    continue\n                # get the large box and get its cordinate\n                last = edgedBoxes[-1]\n                max_x = int(max(last[:,0]))\n                min_x = int( min(last[:,0]))\n                max_y = int(max(last[:,1]))\n                min_y = int(min(last[:,1]))\n                \n                # draw the contour and fill it \n                mask = np.zeros_like(image)\n                cv2.drawContours(mask, edgedContours, len(edgedContours)-1, (255,255,255), -1) \n                \n                # any pixel but the pixels inside the contour is zero\n                image[mask==0] = 0\n                \n                # extract th blood cell\n                image = image[min_y:max_y, min_x:max_x]\n\n                if (np.size(image)==0):\n                    count +=1\n                    continue\n                # resize th image\n                image = cv2.resize(image, image_size)                \n                image = np.reshape(image,image.size )\n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n    print(count)\n    images = np.array(images, dtype = 'float32')\n    labels = np.array(labels, dtype = 'uint8')\n\n    return images, labels","execution_count":23,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"images, labels = load_data()","execution_count":24,"outputs":[{"output_type":"stream","text":"100%|██████████| 2478/2478 [00:10<00:00, 233.35it/s]\n100%|██████████| 2499/2499 [00:10<00:00, 241.31it/s]\n100%|██████████| 2483/2483 [00:10<00:00, 239.76it/s]\n100%|██████████| 2497/2497 [00:10<00:00, 238.19it/s]\n100%|██████████| 620/620 [00:02<00:00, 230.06it/s]\n100%|██████████| 624/624 [00:02<00:00, 236.69it/s]\n100%|██████████| 620/620 [00:02<00:00, 234.80it/s]\n100%|██████████| 623/623 [00:02<00:00, 246.34it/s]\n","name":"stderr"},{"output_type":"stream","text":"298\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Normalization:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"images = images/255.","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding intercept:\n\ndid object detection using opencv by findig edges in the images the extract contours and from contours get image boxes"},{"metadata":{"trusted":true},"cell_type":"code","source":"images = np.append(np.ones((images.shape[0],1)),images,axis=1)","execution_count":26,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Shuffling and Train-Test-Val split:"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"trusted":true},"cell_type":"code","source":"\nimages, labels = shuffle(images, labels, random_state=10)\ntrain_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size = 0.2)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclf1 = SVC(kernel='poly',C=10,random_state=0,cache_size=2048*9)\nclf1.fit(train_images,train_labels)\n","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"SVC(C=10, cache_size=18432, kernel='poly', random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"test_score\",clf1.score(test_images,test_labels))\nprint(\"train_score\",clf1.score(train_images,train_labels))","execution_count":29,"outputs":[{"output_type":"stream","text":"test_score 0.8506172839506173\ntrain_score 0.9975298476739399\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}