{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (97, 2) \n",
      "\n",
      "X_Train [[ 1.      6.1101]\n",
      " [ 1.      5.5277]\n",
      " [ 1.      8.5186]\n",
      " [ 1.      7.0032]\n",
      " [ 1.      5.8598]\n",
      " [ 1.      8.3829]\n",
      " [ 1.      7.4764]\n",
      " [ 1.      8.5781]\n",
      " [ 1.      6.4862]\n",
      " [ 1.      5.0546]\n",
      " [ 1.      5.7107]\n",
      " [ 1.     14.164 ]\n",
      " [ 1.      5.734 ]\n",
      " [ 1.      8.4084]\n",
      " [ 1.      5.6407]\n",
      " [ 1.      5.3794]\n",
      " [ 1.      6.3654]\n",
      " [ 1.      5.1301]\n",
      " [ 1.      6.4296]\n",
      " [ 1.      7.0708]\n",
      " [ 1.      6.1891]\n",
      " [ 1.     20.27  ]\n",
      " [ 1.      5.4901]\n",
      " [ 1.      6.3261]\n",
      " [ 1.      5.5649]\n",
      " [ 1.     18.945 ]\n",
      " [ 1.     12.828 ]\n",
      " [ 1.     10.957 ]\n",
      " [ 1.     13.176 ]\n",
      " [ 1.     22.203 ]\n",
      " [ 1.      5.2524]\n",
      " [ 1.      6.5894]\n",
      " [ 1.      9.2482]\n",
      " [ 1.      5.8918]\n",
      " [ 1.      8.2111]\n",
      " [ 1.      7.9334]\n",
      " [ 1.      8.0959]\n",
      " [ 1.      5.6063]\n",
      " [ 1.     12.836 ]\n",
      " [ 1.      6.3534]\n",
      " [ 1.      5.4069]\n",
      " [ 1.      6.8825]\n",
      " [ 1.     11.708 ]\n",
      " [ 1.      5.7737]\n",
      " [ 1.      7.8247]\n",
      " [ 1.      7.0931]\n",
      " [ 1.      5.0702]\n",
      " [ 1.      5.8014]\n",
      " [ 1.     11.7   ]\n",
      " [ 1.      5.5416]\n",
      " [ 1.      7.5402]\n",
      " [ 1.      5.3077]\n",
      " [ 1.      7.4239]\n",
      " [ 1.      7.6031]\n",
      " [ 1.      6.3328]\n",
      " [ 1.      6.3589]\n",
      " [ 1.      6.2742]\n",
      " [ 1.      5.6397]\n",
      " [ 1.      9.3102]\n",
      " [ 1.      9.4536]\n",
      " [ 1.      8.8254]\n",
      " [ 1.      5.1793]\n",
      " [ 1.     21.279 ]\n",
      " [ 1.     14.908 ]\n",
      " [ 1.     18.959 ]\n",
      " [ 1.      7.2182]\n",
      " [ 1.      8.2951]\n",
      " [ 1.     10.236 ]\n",
      " [ 1.      5.4994]\n",
      " [ 1.     20.341 ]\n",
      " [ 1.     10.136 ]\n",
      " [ 1.      7.3345]\n",
      " [ 1.      6.0062]\n",
      " [ 1.      7.2259]\n",
      " [ 1.      5.0269]\n",
      " [ 1.      6.5479]\n",
      " [ 1.      7.5386]\n",
      " [ 1.      5.0365]\n",
      " [ 1.     10.274 ]\n",
      " [ 1.      5.1077]\n",
      " [ 1.      5.7292]\n",
      " [ 1.      5.1884]] \n",
      " Shape_X_train (82, 2) \n",
      "\n",
      "X_Test [[ 1.      6.3557]\n",
      " [ 1.      9.7687]\n",
      " [ 1.      6.5159]\n",
      " [ 1.      8.5172]\n",
      " [ 1.      9.1802]\n",
      " [ 1.      6.002 ]\n",
      " [ 1.      5.5204]\n",
      " [ 1.      5.0594]\n",
      " [ 1.      5.7077]\n",
      " [ 1.      7.6366]\n",
      " [ 1.      5.8707]\n",
      " [ 1.      5.3054]\n",
      " [ 1.      8.2934]\n",
      " [ 1.     13.394 ]\n",
      " [ 1.      5.4369]] \n",
      " Shape_X_Test (15, 2) \n",
      "\n",
      "y_Train [17.592    9.1302  13.662   11.854    6.8233  11.886    4.3483  12.\n",
      "  6.5987   3.8166   3.2522  15.505    3.1551   7.2258   0.71618  3.5129\n",
      "  5.3048   0.56077  3.6518   5.3893   3.1386  21.767    4.263    5.1875\n",
      "  3.0825  22.638   13.501    7.0467  14.692   24.147   -1.22     5.9966\n",
      " 12.134    1.8495   6.5426   4.5623   4.1164   3.3928  10.117    5.4974\n",
      "  0.55657  3.9115   5.3854   2.4406   6.7318   1.0463   5.1337   1.844\n",
      "  8.0043   1.0179   6.7504   1.8396   4.2885   4.9981   1.4233  -1.4211\n",
      "  2.4756   4.6042   3.9624   5.4141   5.1694  -0.74279 17.929   12.054\n",
      " 17.054    4.8852   5.7442   7.7754   1.0173  20.992    6.6799   4.0259\n",
      "  1.2784   3.3411  -2.6807   0.29678  3.8845   5.7014   6.7526   2.0576\n",
      "  0.47953  0.20421] \n",
      " Shape_y_train (82,) \n",
      "\n",
      "y_Test [0.67861 7.5435  5.3436  4.2415  6.7981  0.92695 0.152   2.8214  1.8451\n",
      " 4.2959  7.2029  1.9869  0.14454 9.0551  0.61705] \n",
      " Shape_y_Test (15,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# Load univariateData\n",
    "data = np.loadtxt('univariateData.txt', delimiter=\",\")\n",
    "# Features\n",
    "X = data[:,0]\n",
    "# Adding the biase feature X0=1\n",
    "X = np.column_stack((np.ones((len(X),1)), X)) # Add a column of ones to x for bias X0=1\n",
    "print(\"X.shape\",X.shape,\"\\n\")\n",
    "# Split our features data into train dataset(85%) and test dataset(15%)\n",
    "X_train= X[0:82,:]\n",
    "X_Test = X[82:,:]\n",
    "print(\"X_Train\",X_train,\"\\n\",\"Shape_X_train\",X_train.shape,\"\\n\")\n",
    "print(\"X_Test\",X_Test,\"\\n\",\"Shape_X_Test\",X_Test.shape,\"\\n\")\n",
    "# Split our Label data into train dataset(85%) and test dataset(15%)\n",
    "y_train= data[0:82,1]\n",
    "y_Test = data[82:,1]\n",
    "print(\"y_Train\",y_train,\"\\n\",\"Shape_y_train\",y_train.shape,\"\\n\")\n",
    "print(\"y_Test\",y_Test,\"\\n\",\"Shape_y_Test\",y_Test.shape,\"\\n\")\n",
    "m = len(y_train) # number of training examples\n",
    "te= len(y_Test)\n",
    "iterations = 1500 # gradient descent sitting\n",
    "alpha = 0.01  # gradient descent sitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeCost(xtrain, ytrain, theta):\n",
    "    J = 0\n",
    "    s = np.power(( xtrain.dot(theta) - np.transpose([ytrain]) ), 2)\n",
    "    J = (1.0/(2*len(xtrain))) * s.sum( axis = 0 )\n",
    "    return J\n",
    "\n",
    "def gradientDescent(xtrain, ytrain, alpha, num_iters):\n",
    "    J_history = np.zeros((num_iters, 1))\n",
    "    theta = np.zeros((2, 1))\n",
    "    for i in range(num_iters):\n",
    "        theta = theta - alpha*(1.0/len(xtrain)) * np.transpose(xtrain).dot(xtrain.dot(theta) - np.transpose([ytrain]))\n",
    "        J_history[i] = computeCost(xtrain, ytrain, theta)\n",
    "    return theta, J_history\n",
    "\n",
    "\n",
    "\n",
    "def LRgd_clf_fit(xtrain, ytrain):\n",
    "    theta,J_history = gradientDescent(xtrain, ytrain, alpha, iterations)\n",
    "    return(theta)\n",
    "\n",
    "\n",
    "def LRgd_clf_predict(xtest):\n",
    "    #X_padded = np.column_stack((np.ones((len(n), 1)), n))\n",
    "    #print(X_padded.shape)\n",
    "    prediction = np.array(xtest).dot(theta)\n",
    "    return(prediction)\n",
    "\n",
    "\n",
    "def performance(ytest,ypred):\n",
    "    J = 0\n",
    "    s = np.power((ypred - np.transpose([ytest])), 2)\n",
    "    J = (1.0 / (2 * len(ytest)) * s.sum(axis=0))\n",
    "    return (J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta \n",
      " [[-3.47777511]\n",
      " [ 1.1733358 ]] \n",
      " Cost_fubction_history \n",
      " [[6.59647878]\n",
      " [6.06637201]\n",
      " [6.05184445]\n",
      " ...\n",
      " [4.7043099 ]\n",
      " [4.7042925 ]\n",
      " [4.70427516]]\n"
     ]
    }
   ],
   "source": [
    "theta, J_history = gradientDescent(X_train, y_train, alpha, iterations)\n",
    "print(\"Theta \\n\",theta,\"\\n Cost_fubction_history \\n\",J_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_fun_result \n",
      " [4.70427516]\n"
     ]
    }
   ],
   "source": [
    "cost_fun_result = computeCost(X_train, y_train, theta)\n",
    "print(\"cost_fun_result \\n\",cost_fun_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Y_Test_predict \n",
      " [[ 3.97959527]\n",
      " [ 7.98419037]\n",
      " [ 4.16756366]\n",
      " [ 6.51576061]\n",
      " [ 7.29368225]\n",
      " [ 3.56458639]\n",
      " [ 2.99950787]\n",
      " [ 2.45860006]\n",
      " [ 3.21927366]\n",
      " [ 5.4825211 ]\n",
      " [ 3.4105274 ]\n",
      " [ 2.74724067]\n",
      " [ 6.25316805]\n",
      " [12.23788466]\n",
      " [ 2.90153433]]\n",
      "\n",
      " performance \n",
      " [3.46698804]\n"
     ]
    }
   ],
   "source": [
    "# fitting the model to our trained data to get the weights of features (theta)\n",
    "theta = LRgd_clf_fit(X_train, y_train)\n",
    "# Use the resulted weights from our classifier to predict the value of label y for test dataset\n",
    "ypred=LRgd_clf_predict(X_Test)\n",
    "print(\"\\n Y_Test_predict \\n\",ypred)\n",
    "\n",
    "print(\"\\n performance \\n\",performance(y_Test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Y_Trained_predict \n",
      " [[ 3.69142399]\n",
      " [ 3.00807322]\n",
      " [ 6.51740328]\n",
      " [ 4.7393302 ]\n",
      " [ 3.39773804]\n",
      " [ 6.35818161]\n",
      " [ 5.2945527 ]\n",
      " [ 6.58721676]\n",
      " [ 4.13271559]\n",
      " [ 2.45296805]\n",
      " [ 3.22279367]\n",
      " [13.14135323]\n",
      " [ 3.2501324 ]\n",
      " [ 6.38810167]\n",
      " [ 3.14066017]\n",
      " [ 2.83406752]\n",
      " [ 3.99097662]\n",
      " [ 2.5415549 ]\n",
      " [ 4.06630478]\n",
      " [ 4.8186477 ]\n",
      " [ 3.78411752]\n",
      " [20.30574165]\n",
      " [ 2.96395579]\n",
      " [ 3.94486453]\n",
      " [ 3.05172131]\n",
      " [18.75107171]\n",
      " [11.57377659]\n",
      " [ 9.3784653 ]\n",
      " [11.98209745]\n",
      " [22.57379976]\n",
      " [ 2.68505387]\n",
      " [ 4.25380384]\n",
      " [ 7.37346908]\n",
      " [ 3.43528479]\n",
      " [ 6.15660252]\n",
      " [ 5.83076717]\n",
      " [ 6.02143423]\n",
      " [ 3.10029741]\n",
      " [11.58316328]\n",
      " [ 3.97689659]\n",
      " [ 2.86633425]\n",
      " [ 4.59770857]\n",
      " [10.25964049]\n",
      " [ 3.29671383]\n",
      " [ 5.70322556]\n",
      " [ 4.84481309]\n",
      " [ 2.47127209]\n",
      " [ 3.32921523]\n",
      " [10.25025381]\n",
      " [ 3.02438259]\n",
      " [ 5.36941153]\n",
      " [ 2.74993934]\n",
      " [ 5.23295257]\n",
      " [ 5.44321435]\n",
      " [ 3.95272588]\n",
      " [ 3.98334994]\n",
      " [ 3.8839684 ]\n",
      " [ 3.13948683]\n",
      " [ 7.4462159 ]\n",
      " [ 7.61447226]\n",
      " [ 6.8773827 ]\n",
      " [ 2.59928303]\n",
      " [21.48963748]\n",
      " [14.01431507]\n",
      " [18.76749841]\n",
      " [ 4.9915974 ]\n",
      " [ 6.25516273]\n",
      " [ 8.53249019]\n",
      " [ 2.97486782]\n",
      " [20.38904849]\n",
      " [ 8.41515661]\n",
      " [ 5.12805635]\n",
      " [ 3.5695144 ]\n",
      " [ 5.00063208]\n",
      " [ 2.42046665]\n",
      " [ 4.20511041]\n",
      " [ 5.36753419]\n",
      " [ 2.43173067]\n",
      " [ 8.57707695]\n",
      " [ 2.51527218]\n",
      " [ 3.24450038]\n",
      " [ 2.60996038]]\n",
      "\n",
      " performance \n",
      " [4.70427516]\n"
     ]
    }
   ],
   "source": [
    "#predicted_y for X_Train dataset\n",
    "ypred_trained=LRgd_clf_predict(X_train)\n",
    "print(\"\\n Y_Trained_predict \\n\",ypred_trained)\n",
    "\n",
    "print(\"\\n performance \\n\",performance(y_train,ypred_trained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
