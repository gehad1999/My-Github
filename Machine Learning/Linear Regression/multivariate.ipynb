{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xdata \n",
      " [[ 1.31415422e-01 -2.26093368e-01]\n",
      " [-5.09640698e-01 -2.26093368e-01]\n",
      " [ 5.07908699e-01 -2.26093368e-01]\n",
      " [-7.43677059e-01 -1.55439190e+00]\n",
      " [ 1.27107075e+00  1.10220517e+00]\n",
      " [-1.99450507e-02  1.10220517e+00]\n",
      " [-5.93588523e-01 -2.26093368e-01]\n",
      " [-7.29685755e-01 -2.26093368e-01]\n",
      " [-7.89466782e-01 -2.26093368e-01]\n",
      " [-6.44465993e-01 -2.26093368e-01]\n",
      " [-7.71822042e-02  1.10220517e+00]\n",
      " [-8.65999486e-04 -2.26093368e-01]\n",
      " [-1.40779041e-01 -2.26093368e-01]\n",
      " [ 3.15099326e+00  2.43050370e+00]\n",
      " [-9.31923697e-01 -2.26093368e-01]\n",
      " [ 3.80715024e-01  1.10220517e+00]\n",
      " [-8.65782986e-01 -1.55439190e+00]\n",
      " [-9.72625673e-01 -2.26093368e-01]\n",
      " [ 7.73743478e-01  1.10220517e+00]\n",
      " [ 1.31050078e+00  1.10220517e+00]\n",
      " [-2.97227261e-01 -2.26093368e-01]\n",
      " [-1.43322915e-01 -1.55439190e+00]\n",
      " [-5.04552951e-01 -2.26093368e-01]\n",
      " [-4.91995958e-02  1.10220517e+00]\n",
      " [ 2.40309445e+00 -2.26093368e-01]\n",
      " [-1.14560907e+00 -2.26093368e-01]\n",
      " [-6.90255715e-01 -2.26093368e-01]\n",
      " [ 6.68172729e-01 -2.26093368e-01]\n",
      " [ 2.53521350e-01 -2.26093368e-01]\n",
      " [ 8.09357707e-01 -2.26093368e-01]\n",
      " [-2.05647815e-01 -1.55439190e+00]\n",
      " [-1.27280274e+00 -2.88269044e+00]\n",
      " [ 5.00114703e-02  1.10220517e+00]\n",
      " [ 1.44532608e+00 -2.26093368e-01]\n",
      " [-2.41262044e-01  1.10220517e+00]\n",
      " [-7.16966387e-01 -2.26093368e-01]\n",
      " [-9.68809863e-01 -2.26093368e-01]\n",
      " [ 1.67029651e-01  1.10220517e+00]\n",
      " [ 2.81647389e+00  1.10220517e+00]\n",
      " [ 2.05187753e-01  1.10220517e+00]\n",
      " [-4.28236746e-01 -1.55439190e+00]\n",
      " [ 3.01854946e-01 -2.26093368e-01]\n",
      " [ 7.20322135e-01  1.10220517e+00]\n",
      " [-1.01841540e+00 -2.26093368e-01]\n",
      " [-1.46104938e+00 -1.55439190e+00]\n",
      " [-1.89112638e-01  1.10220517e+00]\n",
      " [-1.01459959e+00 -2.26093368e-01]] mean \n",
      " [[2000.68085106    3.17021277]] standard_deviation \n",
      " [[7.86202619e+02 7.52842809e-01]] \n",
      "\n",
      "X.shape \n",
      " (47, 3) \n",
      "\n",
      "X_Train [[ 1.00000000e+00  1.31415422e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -5.09640698e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00  5.07908699e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -7.43677059e-01 -1.55439190e+00]\n",
      " [ 1.00000000e+00  1.27107075e+00  1.10220517e+00]\n",
      " [ 1.00000000e+00 -1.99450507e-02  1.10220517e+00]\n",
      " [ 1.00000000e+00 -5.93588523e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -7.29685755e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -7.89466782e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -6.44465993e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -7.71822042e-02  1.10220517e+00]\n",
      " [ 1.00000000e+00 -8.65999486e-04 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -1.40779041e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00  3.15099326e+00  2.43050370e+00]\n",
      " [ 1.00000000e+00 -9.31923697e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00  3.80715024e-01  1.10220517e+00]\n",
      " [ 1.00000000e+00 -8.65782986e-01 -1.55439190e+00]\n",
      " [ 1.00000000e+00 -9.72625673e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00  7.73743478e-01  1.10220517e+00]\n",
      " [ 1.00000000e+00  1.31050078e+00  1.10220517e+00]\n",
      " [ 1.00000000e+00 -2.97227261e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -1.43322915e-01 -1.55439190e+00]\n",
      " [ 1.00000000e+00 -5.04552951e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -4.91995958e-02  1.10220517e+00]\n",
      " [ 1.00000000e+00  2.40309445e+00 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -1.14560907e+00 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -6.90255715e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00  6.68172729e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00  2.53521350e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00  8.09357707e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -2.05647815e-01 -1.55439190e+00]\n",
      " [ 1.00000000e+00 -1.27280274e+00 -2.88269044e+00]\n",
      " [ 1.00000000e+00  5.00114703e-02  1.10220517e+00]\n",
      " [ 1.00000000e+00  1.44532608e+00 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -2.41262044e-01  1.10220517e+00]\n",
      " [ 1.00000000e+00 -7.16966387e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00 -9.68809863e-01 -2.26093368e-01]\n",
      " [ 1.00000000e+00  1.67029651e-01  1.10220517e+00]\n",
      " [ 1.00000000e+00  2.81647389e+00  1.10220517e+00]] \n",
      " Shape_X_train (39, 3)\n",
      "X_Test [[ 1.          0.20518775  1.10220517]\n",
      " [ 1.         -0.42823675 -1.5543919 ]\n",
      " [ 1.          0.30185495 -0.22609337]\n",
      " [ 1.          0.72032214  1.10220517]\n",
      " [ 1.         -1.0184154  -0.22609337]\n",
      " [ 1.         -1.46104938 -1.5543919 ]\n",
      " [ 1.         -0.18911264  1.10220517]\n",
      " [ 1.         -1.01459959 -0.22609337]] \n",
      " Shape_X_Test (8, 3)\n",
      "y_Train [399900. 329900. 369000. 232000. 539900. 299900. 314900. 198999. 212000.\n",
      " 242500. 239999. 347000. 329999. 699900. 259900. 449900. 299900. 199900.\n",
      " 499998. 599000. 252900. 255000. 242900. 259900. 573900. 249900. 464500.\n",
      " 469000. 475000. 299900. 349900. 169900. 314900. 579900. 285900. 249900.\n",
      " 229900. 345000. 549000.] \n",
      " Shape_y_train (39,)\n",
      "y_Test [287000. 368500. 329900. 314000. 299000. 179900. 299900. 239500.] \n",
      " Shape_y_Test (8,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# Load multivariateData\n",
    "data = np.loadtxt('multivariateData.txt', delimiter=\",\")\n",
    "\n",
    "# Features\n",
    "Xdata = data[:,:2]\n",
    "\n",
    "# Feature Normalization\n",
    "def featureNormalize(Xdata):\n",
    "    X_norm = Xdata\n",
    "    mu    = np.zeros((1, Xdata.shape[1])) # mean (for each feature)\n",
    "    s = np.zeros((1, Xdata.shape[1]))    # standard deviation (range) of each feature values, (max-minimum but in implementation we use in calculating it the standard deviation)\n",
    "    for i in range(Xdata.shape[1]):\n",
    "    \tmu[:,i] = np.mean(Xdata[:,i])  # the mean for (first feature) , then in 2nd iteration (the mean for all data of the second feature)\n",
    "    \ts[:,i] = np.std(Xdata[:,i])   # the standard deviation (range which will be used in the devision for getting normalized data)\n",
    "    \tX_norm[:,i] = (Xdata[:,i] - float(mu[:,i]))/float(s[:,i])\n",
    "    return X_norm, mu, s\n",
    "\n",
    "# Xdata (Data after normalization)\n",
    "Xdata , mu, s= featureNormalize(Xdata) #47row\n",
    "print(\"Xdata \\n\",Xdata,\"mean \\n\", mu,\"standard_deviation \\n\",s,\"\\n\")\n",
    "\n",
    "# Adding the biase feature X0=1\n",
    "Xdata = np.column_stack((np.ones((len(Xdata),1)), Xdata)) # Add a column of ones to x for bias X0=1\n",
    "print(\"X.shape \\n\",Xdata.shape,\"\\n\")\n",
    "\n",
    "# Split our features data into train dataset(85%) and test dataset(15%)\n",
    "X_train= Xdata[0:39,:]\n",
    "X_Test = Xdata[39:,:]\n",
    "print(\"X_Train\",X_train,\"\\n\",\"Shape_X_train\",X_train.shape)\n",
    "print(\"X_Test\",X_Test,\"\\n\",\"Shape_X_Test\",X_Test.shape)\n",
    "\n",
    "# Split our Label data into train dataset(85%) and test dataset(15%)\n",
    "y_train= data[0:39,2]\n",
    "y_Test = data[39:,2]\n",
    "print(\"y_Train\",y_train,\"\\n\",\"Shape_y_train\",y_train.shape)\n",
    "print(\"y_Test\",y_Test,\"\\n\",\"Shape_y_Test\",y_Test.shape)\n",
    "m = len(y_train) # number of training examples\n",
    "te= len(y_Test)\n",
    "\n",
    "# Set up for gradient descent\n",
    "# Choose alpha value\n",
    "iterations = 1500 # gradient descent sitting\n",
    "alpha = 0.01  # gradient descent sitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeCost(xtrain, ytrain, theta):\n",
    "    J = 0\n",
    "    s = np.power(( xtrain.dot(theta) - np.transpose([ytrain]) ), 2)\n",
    "    J = (1.0/(2*len(xtrain)) * s.sum( axis = 0 ))\n",
    "    return J\n",
    "\n",
    "\n",
    "def gradientDescentMulti(xtrain, ytrain, alpha, num_iters):\n",
    "    J_history = np.zeros((num_iters, 1))\n",
    "    theta = np.zeros((3, 1))\n",
    "    for i in range(num_iters):\n",
    "        theta = theta - alpha*(1.0/len(ytrain)) * np.transpose(xtrain).dot(xtrain.dot(theta) - np.transpose([ytrain]))\n",
    "        J_history[i] = computeCost(xtrain, ytrain, theta)\n",
    "        #print(\"J_history\", theta)\n",
    "    return theta , J_history\n",
    "\n",
    "\n",
    "def LRgd_clf_fit(xtrain, ytrain):\n",
    "    theta , cost = gradientDescentMulti(xtrain, ytrain, alpha, iterations)\n",
    "    return(theta)\n",
    "\n",
    "\n",
    "def LRgd_clf_predict(xtest):\n",
    "    prediction = np.array(xtest).dot(theta)\n",
    "    return(prediction)\n",
    "\n",
    "def performance(ytest,ypred):\n",
    "    J = 0\n",
    "    s = np.power((ypred - np.transpose([ytest])), 2)\n",
    "    J = (1.0 / (2 * len(ytest)) * s.sum(axis=0))\n",
    "    return (J)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta \n",
      " [[342680.09681975]\n",
      " [109883.64254241]\n",
      " [   678.94046348]] \n",
      " \n",
      " Cost_fubction_history \n",
      " \n",
      " [[6.86657428e+10]\n",
      " [6.72244819e+10]\n",
      " [6.58157948e+10]\n",
      " ...\n",
      " [2.10390558e+09]\n",
      " [2.10390558e+09]\n",
      " [2.10390557e+09]]\n"
     ]
    }
   ],
   "source": [
    "theta, J_history = gradientDescentMulti(X_train, y_train, alpha, iterations)\n",
    "print(\"Theta \\n\",theta,\"\\n \\n Cost_fubction_history \\n \\n\",J_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_fun_result \n",
      " [2.10390557e+09]\n"
     ]
    }
   ],
   "source": [
    "cost_fun_result = computeCost(X_train, y_train, theta)\n",
    "print(\"cost_fun_result \\n\",cost_fun_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[342680.09681975]\n",
      " [109883.64254241]\n",
      " [   678.94046348]]\n",
      "\n",
      " Y_Test_predict \n",
      " [[365975.20623843]\n",
      " [294568.54375196]\n",
      " [375695.51385738]\n",
      " [422580.04851284]\n",
      " [230619.3995837 ]\n",
      " [181079.32911784]\n",
      " [322648.04301604]\n",
      " [231038.69471166]]\n",
      "\n",
      " performance \n",
      " [1.92851025e+09]\n"
     ]
    }
   ],
   "source": [
    "# fitting the model to our trained data to get the weights of features (theta)\n",
    "theta , j= LRgd_clf_fit(X_train, y_train)\n",
    "print(theta)\n",
    "# Use the resulted weights from our classifier to predict the value of label y for test dataset\n",
    "ypred=LRgd_clf_predict(X_Test)\n",
    "print(\"\\n Y_Test_predict \\n\",ypred)\n",
    "\n",
    "print(\"\\n performance \\n\",performance(y_Test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Y_Trained_predict \n",
      " [[356966.99814189]\n",
      " [286525.41664485]\n",
      " [398337.45076714]\n",
      " [259906.81317405]\n",
      " [483098.31198153]\n",
      " [341236.79368887]\n",
      " [277300.92382976]\n",
      " [262346.0642659 ]\n",
      " [255777.10726122]\n",
      " [271710.32212365]\n",
      " [334947.36676949]\n",
      " [342431.43370599]\n",
      " [327057.27901418]\n",
      " [690572.88064513]\n",
      " [240123.4224841 ]\n",
      " [385262.78212453]\n",
      " [246489.36907938]\n",
      " [235650.94111921]\n",
      " [428450.18030426]\n",
      " [487431.02830377]\n",
      " [309866.17876788]\n",
      " [325875.9133062 ]\n",
      " [287084.47681546]\n",
      " [338022.19770786]\n",
      " [606587.36431991]\n",
      " [216642.89531842]\n",
      " [266678.78058814]\n",
      " [415947.8461414 ]\n",
      " [370384.44223657]\n",
      " [431461.76587587]\n",
      " [319027.42621621]\n",
      " [200862.71980779]\n",
      " [348923.87103478]\n",
      " [501344.2872023 ]\n",
      " [316917.67626728]\n",
      " [263743.71469243]\n",
      " [236070.23624717]\n",
      " [361782.25495884]\n",
      " [652912.83880476]]\n",
      "\n",
      " performance \n",
      " [2.10390557e+09]\n"
     ]
    }
   ],
   "source": [
    "#predicted_y for X_Train dataset\n",
    "ypred_trained=LRgd_clf_predict(X_train)\n",
    "print(\"\\n Y_Trained_predict \\n\",ypred_trained)\n",
    "\n",
    "print(\"\\n performance \\n\",performance(y_train,ypred_trained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
